"""Initial migration

Revision ID: bb60f1a85233
Revises: 
Create Date: 2025-12-01 17:59:06.473816

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'bb60f1a85233'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('Cases')
    with op.batch_alter_table('case_files', schema=None) as batch_op:
        batch_op.add_column(sa.Column('report_path', sa.String(length=512), nullable=True))
        batch_op.add_column(sa.Column('notes', sa.Text(), nullable=True))
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False,
               autoincrement=True)
        batch_op.alter_column('case_id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False)
        batch_op.alter_column('file_path',
               existing_type=sa.TEXT(),
               type_=sa.String(length=512),
               existing_nullable=False)
        batch_op.alter_column('checksum',
               existing_type=sa.VARCHAR(length=128),
               nullable=False)
        batch_op.alter_column('mime_type',
               existing_type=sa.TEXT(),
               type_=sa.String(length=100),
               existing_nullable=True)
        batch_op.alter_column('stored_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.drop_constraint(batch_op.f('case_files_case_id_file_path_key'), type_='unique')
        batch_op.drop_index(batch_op.f('idx_case_files_case_id'))

    with op.batch_alter_table('cases', schema=None) as batch_op:
        batch_op.alter_column('id',
               existing_type=sa.BIGINT(),
               type_=sa.Integer(),
               existing_nullable=False,
               autoincrement=True,
               existing_server_default=sa.text("nextval('cases_id_seq'::regclass)"))
        batch_op.alter_column('name',
               existing_type=sa.TEXT(),
               type_=sa.String(length=255),
               existing_nullable=False)
        batch_op.alter_column('status',
               existing_type=postgresql.ENUM('queued', 'processing', 'completed', 'failed', 'archived', name='case_status'),
               type_=sa.String(length=20),
               existing_nullable=False,
               existing_server_default=sa.text("'queued'::case_status"))
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('metadata',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               nullable=False,
               existing_server_default=sa.text("'{}'::jsonb"))
        batch_op.drop_index(batch_op.f('idx_cases_status_created_at'))

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('cases', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_cases_status_created_at'), ['status', 'created_at'], unique=False)
        batch_op.alter_column('metadata',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               nullable=True,
               existing_server_default=sa.text("'{}'::jsonb"))
        batch_op.alter_column('updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('status',
               existing_type=sa.String(length=20),
               type_=postgresql.ENUM('queued', 'processing', 'completed', 'failed', 'archived', name='case_status'),
               existing_nullable=False,
               existing_server_default=sa.text("'queued'::case_status"))
        batch_op.alter_column('name',
               existing_type=sa.String(length=255),
               type_=sa.TEXT(),
               existing_nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True,
               existing_server_default=sa.text("nextval('cases_id_seq'::regclass)"))

    with op.batch_alter_table('case_files', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_case_files_case_id'), ['case_id'], unique=False)
        batch_op.create_unique_constraint(batch_op.f('case_files_case_id_file_path_key'), ['case_id', 'file_path'], postgresql_nulls_not_distinct=False)
        batch_op.alter_column('stored_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=False,
               existing_server_default=sa.text('now()'))
        batch_op.alter_column('mime_type',
               existing_type=sa.String(length=100),
               type_=sa.TEXT(),
               existing_nullable=True)
        batch_op.alter_column('checksum',
               existing_type=sa.VARCHAR(length=128),
               nullable=True)
        batch_op.alter_column('file_path',
               existing_type=sa.String(length=512),
               type_=sa.TEXT(),
               existing_nullable=False)
        batch_op.alter_column('case_id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False)
        batch_op.alter_column('id',
               existing_type=sa.Integer(),
               type_=sa.BIGINT(),
               existing_nullable=False,
               autoincrement=True)
        batch_op.drop_column('notes')
        batch_op.drop_column('report_path')

    op.create_table('Cases',
    sa.Column('Id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('filename', postgresql.ARRAY(sa.VARCHAR(length=255)), autoincrement=False, nullable=False),
    sa.Column('filepath', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('size', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('status', postgresql.ARRAY(sa.VARCHAR(length=50)), autoincrement=False, nullable=True),
    sa.Column('report_path', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('hash', postgresql.ARRAY(sa.VARCHAR(length=64)), autoincrement=False, nullable=True),
    sa.Column('noted', sa.TEXT(), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('Id', name=op.f('Cases_pkey'))
    )
    # ### end Alembic commands ###
